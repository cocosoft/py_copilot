# Py Copilot æŠ€èƒ½å¼€å‘æœ€ä½³å®è·µ

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›Py CopilotæŠ€èƒ½å¼€å‘çš„æœ€ä½³å®è·µæ¡ˆä¾‹ï¼Œæ¶µç›–ä»£ç è´¨é‡ã€æ€§èƒ½ä¼˜åŒ–ã€å®‰å…¨æ€§ã€ç”¨æˆ·ä½“éªŒç­‰æ–¹é¢çš„å®è·µç»éªŒã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡æœ€ä½³å®è·µ

### 1. æ¨¡å—åŒ–è®¾è®¡

**æ¡ˆä¾‹ï¼šæ•°æ®åˆ†ææŠ€èƒ½**

```python
# è‰¯å¥½çš„æ¨¡å—åŒ–è®¾è®¡
# main.py
"""æ•°æ®åˆ†ææŠ€èƒ½ - æ¨¡å—åŒ–è®¾è®¡ç¤ºä¾‹"""

from .data_loader import DataLoader
from .data_processor import DataProcessor
from .result_formatter import ResultFormatter
from .error_handler import ErrorHandler

class DataAnalysisSkill:
    def __init__(self):
        self.loader = DataLoader()
        self.processor = DataProcessor()
        self.formatter = ResultFormatter()
        self.error_handler = ErrorHandler()
    
    def execute(self, input_data):
        try:
            # 1. æ•°æ®åŠ è½½
            data = self.loader.load(input_data)
            
            # 2. æ•°æ®å¤„ç†
            result = self.processor.process(data)
            
            # 3. ç»“æœæ ¼å¼åŒ–
            formatted_result = self.formatter.format(result)
            
            return {
                "success": True,
                "result": formatted_result
            }
            
        except Exception as e:
            return self.error_handler.handle(e)

# æ•°æ®åŠ è½½æ¨¡å—
data_loader.py
class DataLoader:
    def load(self, input_data):
        # æ•°æ®åŠ è½½é€»è¾‘
        pass

# æ•°æ®å¤„ç†æ¨¡å—  
data_processor.py
class DataProcessor:
    def process(self, data):
        # æ•°æ®å¤„ç†é€»è¾‘
        pass
```

**ä¼˜åŠ¿**ï¼š
- èŒè´£åˆ†ç¦»ï¼Œä¾¿äºæµ‹è¯•å’Œç»´æŠ¤
- ä»£ç å¤ç”¨æ€§é«˜
- æ˜“äºæ‰©å±•æ–°åŠŸèƒ½

### 2. é…ç½®é©±åŠ¨è®¾è®¡

**æ¡ˆä¾‹ï¼šæ–‡ä»¶å¤„ç†æŠ€èƒ½**

```python
# skill.json
{
    "config_schema": {
        "type": "object",
        "properties": {
            "supported_formats": {
                "type": "array",
                "default": ["txt", "csv", "json"],
                "description": "æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"
            },
            "max_file_size": {
                "type": "integer", 
                "default": 10485760,
                "description": "æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰"
            }
        }
    }
}

# main.py
class FileProcessor:
    def __init__(self, config):
        self.supported_formats = config.get("supported_formats", ["txt", "csv"])
        self.max_file_size = config.get("max_file_size", 10485760)
    
    def process_file(self, file_path):
        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        if not self._is_supported_format(file_path):
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        if not self._is_valid_size(file_path):
            raise ValueError("æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶")
        
        # å¤„ç†é€»è¾‘...
```

**ä¼˜åŠ¿**ï¼š
- è¡Œä¸ºå¯é…ç½®ï¼Œæ— éœ€ä¿®æ”¹ä»£ç 
- ç”¨æˆ·å¯æ ¹æ®éœ€æ±‚è°ƒæ•´å‚æ•°
- ä¾¿äºA/Bæµ‹è¯•å’Œæ€§èƒ½è°ƒä¼˜

## âš¡ æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ

### 1. å¼‚æ­¥å¤„ç†

**æ¡ˆä¾‹ï¼šç½‘ç»œè¯·æ±‚å¯†é›†å‹æŠ€èƒ½**

```python
import asyncio
import aiohttp
from typing import List, Dict

class WebScrapingSkill:
    async def execute(self, input_data: Dict) -> Dict:
        urls = input_data.get("urls", [])
        
        # å¼‚æ­¥å¹¶å‘å¤„ç†
        tasks = [self._fetch_url(url) for url in urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return {
            "success": True,
            "results": results
        }
    
    async def _fetch_url(self, url: str) -> Dict:
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                return {
                    "url": url,
                    "status": response.status,
                    "content": await response.text()
                }
```

**æ€§èƒ½æå‡**ï¼š
- ç›¸æ¯”åŒæ­¥è¯·æ±‚ï¼Œæ€§èƒ½æå‡5-10å€
- æ›´å¥½çš„èµ„æºåˆ©ç”¨ç‡
- æ”¯æŒå¤§è§„æ¨¡å¹¶å‘å¤„ç†

### 2. ç¼“å­˜ç­–ç•¥

**æ¡ˆä¾‹ï¼šæ•°æ®æŸ¥è¯¢æŠ€èƒ½**

```python
import time
from functools import lru_cache
from typing import Any

class DataQuerySkill:
    def __init__(self):
        self._cache = {}
        self._cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜
    
    @lru_cache(maxsize=1000)
    def expensive_calculation(self, params: tuple) -> Any:
        """ä½¿ç”¨LRUç¼“å­˜æ˜‚è´µè®¡ç®—"""
        # æ¨¡æ‹Ÿæ˜‚è´µè®¡ç®—
        time.sleep(0.1)
        return f"result_for_{params}"
    
    def query_with_ttl_cache(self, key: str, query_func) -> Any:
        """å¸¦TTLçš„ç¼“å­˜"""
        current_time = time.time()
        
        if key in self._cache:
            cached_data, timestamp = self._cache[key]
            if current_time - timestamp < self._cache_ttl:
                return cached_data
        
        # æ‰§è¡ŒæŸ¥è¯¢
        result = query_func()
        self._cache[key] = (result, current_time)
        
        return result
```

**æ€§èƒ½æ•°æ®**ï¼š
- LRUç¼“å­˜ï¼šå‡å°‘95%çš„è®¡ç®—æ—¶é—´
- TTLç¼“å­˜ï¼šå‡å°‘80%çš„æ•°æ®åº“æŸ¥è¯¢

### 3. æ‰¹é‡å¤„ç†

**æ¡ˆä¾‹ï¼šå›¾åƒå¤„ç†æŠ€èƒ½**

```python
import cv2
import numpy as np
from typing import List

class ImageProcessingSkill:
    def process_batch(self, image_paths: List[str]) -> List[Dict]:
        """æ‰¹é‡å¤„ç†å›¾åƒ"""
        results = []
        
        # æ‰¹é‡åŠ è½½å›¾åƒ
        images = [self._load_image(path) for path in image_paths]
        
        # æ‰¹é‡å¤„ç†ï¼ˆä½¿ç”¨å‘é‡åŒ–æ“ä½œï¼‰
        processed_images = self._batch_process(images)
        
        # æ‰¹é‡ä¿å­˜ç»“æœ
        for i, (path, processed_img) in enumerate(zip(image_paths, processed_images)):
            result_path = self._save_result(processed_img, path)
            results.append({
                "original": path,
                "processed": result_path,
                "index": i
            })
        
        return results
    
    def _batch_process(self, images: List[np.ndarray]) -> List[np.ndarray]:
        """æ‰¹é‡å¤„ç†å›¾åƒï¼ˆå‘é‡åŒ–æ“ä½œï¼‰"""
        # ä½¿ç”¨NumPyå‘é‡åŒ–æ“ä½œæé«˜æ€§èƒ½
        images_array = np.array(images)
        
        # æ‰¹é‡åº”ç”¨æ»¤é•œ
        processed_array = cv2.GaussianBlur(images_array, (5, 5), 0)
        
        return list(processed_array)
```

**æ€§èƒ½å¯¹æ¯”**ï¼š
- å•å¼ å¤„ç†ï¼š100å¼ å›¾åƒéœ€è¦10ç§’
- æ‰¹é‡å¤„ç†ï¼š100å¼ å›¾åƒéœ€è¦2ç§’ï¼ˆ5å€æå‡ï¼‰

## ğŸ”’ å®‰å…¨æ€§æœ€ä½³å®è·µ

### 1. è¾“å…¥éªŒè¯

**æ¡ˆä¾‹ï¼šæ–‡ä»¶ä¸Šä¼ æŠ€èƒ½**

```python
import os
import magic
from pathlib import Path

class FileUploadSkill:
    def __init__(self):
        self.allowed_extensions = {'.txt', '.csv', '.json', '.pdf'}
        self.allowed_mime_types = {
            'text/plain', 'text/csv', 'application/json', 'application/pdf'
        }
        self.max_file_size = 10 * 1024 * 1024  # 10MB
    
    def validate_file(self, file_path: str) -> Dict:
        """å…¨é¢æ–‡ä»¶éªŒè¯"""
        errors = []
        
        # 1. è·¯å¾„å®‰å…¨æ€§æ£€æŸ¥
        if not self._is_safe_path(file_path):
            errors.append("æ–‡ä»¶è·¯å¾„ä¸å®‰å…¨")
        
        # 2. æ–‡ä»¶æ‰©å±•åæ£€æŸ¥
        if not self._has_allowed_extension(file_path):
            errors.append("æ–‡ä»¶æ‰©å±•åä¸è¢«å…è®¸")
        
        # 3. MIMEç±»å‹æ£€æŸ¥
        if not self._has_allowed_mime_type(file_path):
            errors.append("æ–‡ä»¶ç±»å‹ä¸è¢«å…è®¸")
        
        # 4. æ–‡ä»¶å¤§å°æ£€æŸ¥
        if not self._is_valid_size(file_path):
            errors.append("æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶")
        
        return {
            "valid": len(errors) == 0,
            "errors": errors
        }
    
    def _is_safe_path(self, file_path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶è·¯å¾„å®‰å…¨æ€§"""
        try:
            # è§£æè·¯å¾„å¹¶æ£€æŸ¥æ˜¯å¦åŒ…å«å±é™©å­—ç¬¦
            path = Path(file_path).resolve()
            
            # æ£€æŸ¥æ˜¯å¦åœ¨å®‰å…¨ç›®å½•å†…
            safe_dirs = ['/tmp/uploads', '/app/data']
            return any(str(path).startswith(safe_dir) for safe_dir in safe_dirs)
            
        except Exception:
            return False
```

**å®‰å…¨ç‰¹æ€§**ï¼š
- å¤šå±‚éªŒè¯æœºåˆ¶
- è·¯å¾„éå†æ”»å‡»é˜²æŠ¤
- æ–‡ä»¶ç±»å‹æ¬ºéª—é˜²æŠ¤

### 2. æƒé™æ§åˆ¶

**æ¡ˆä¾‹ï¼šæ•°æ®åº“æ“ä½œæŠ€èƒ½**

```python
import sqlite3
from contextlib import contextmanager

class DatabaseSkill:
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.user_permissions = {
            "read_only": ["SELECT"],
            "read_write": ["SELECT", "INSERT", "UPDATE"],
            "admin": ["SELECT", "INSERT", "UPDATE", "DELETE", "CREATE"]
        }
    
    @contextmanager
    def get_connection(self, user_role: str = "read_only"):
        """å¸¦æƒé™æ§åˆ¶çš„æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(self.db_path)
        
        try:
            # è®¾ç½®æƒé™é™åˆ¶
            self._apply_permissions(conn, user_role)
            yield conn
            
        finally:
            conn.close()
    
    def _apply_permissions(self, conn, user_role: str):
        """åº”ç”¨æƒé™é™åˆ¶"""
        allowed_operations = self.user_permissions.get(user_role, [])
        
        # åˆ›å»ºæƒé™æ£€æŸ¥å‡½æ•°
        def permission_checker(operation, table):
            if operation.upper() not in allowed_operations:
                raise PermissionError(f"è§’è‰² {user_role} æ— æƒæ‰§è¡Œ {operation} æ“ä½œ")
            return True
        
        # æ³¨å†Œæƒé™æ£€æŸ¥ï¼ˆSQLiteæ‰©å±•ï¼‰
        conn.create_function("check_permission", 2, permission_checker)
```

**å®‰å…¨ä¼˜åŠ¿**ï¼š
- åŸºäºè§’è‰²çš„æƒé™æ§åˆ¶
- æ“ä½œçº§åˆ«çš„æƒé™æ£€æŸ¥
- é˜²æ­¢SQLæ³¨å…¥æ”»å‡»

## ğŸ¨ ç”¨æˆ·ä½“éªŒæœ€ä½³å®è·µ

### 1. æ¸è¿›å¼åé¦ˆ

**æ¡ˆä¾‹ï¼šå¤§æ•°æ®å¤„ç†æŠ€èƒ½**

```python
import time
import asyncio
from typing import Callable, Dict, Any

class BigDataProcessingSkill:
    def __init__(self):
        self.progress_handlers = []
    
    def add_progress_handler(self, handler: Callable):
        """æ·»åŠ è¿›åº¦å¤„ç†å‡½æ•°"""
        self.progress_handlers.append(handler)
    
    async def process_with_progress(self, data: Any) -> Dict:
        """å¸¦è¿›åº¦åé¦ˆçš„æ•°æ®å¤„ç†"""
        total_steps = 5
        
        # æ­¥éª¤1: æ•°æ®éªŒè¯ (10%)
        await self._update_progress(10, "æ­£åœ¨éªŒè¯æ•°æ®...")
        self._validate_data(data)
        
        # æ­¥éª¤2: æ•°æ®é¢„å¤„ç† (25%)
        await self._update_progress(25, "æ­£åœ¨é¢„å¤„ç†æ•°æ®...")
        preprocessed_data = await self._preprocess_data(data)
        
        # æ­¥éª¤3: æ ¸å¿ƒå¤„ç† (50%)
        await self._update_progress(50, "æ­£åœ¨å¤„ç†æ•°æ®...")
        result = await self._core_processing(preprocessed_data)
        
        # æ­¥éª¤4: ç»“æœæ ¼å¼åŒ– (80%)
        await self._update_progress(80, "æ­£åœ¨æ ¼å¼åŒ–ç»“æœ...")
        formatted_result = self._format_result(result)
        
        # æ­¥éª¤5: å®Œæˆ (100%)
        await self._update_progress(100, "å¤„ç†å®Œæˆ!")
        
        return {
            "success": True,
            "result": formatted_result,
            "progress": 100
        }
    
    async def _update_progress(self, percentage: int, message: str):
        """æ›´æ–°è¿›åº¦ä¿¡æ¯"""
        for handler in self.progress_handlers:
            await handler({
                "percentage": percentage,
                "message": message,
                "timestamp": time.time()
            })
```

**ç”¨æˆ·ä½“éªŒæå‡**ï¼š
- å®æ—¶è¿›åº¦åé¦ˆ
- æ˜ç¡®çš„çŠ¶æ€ä¿¡æ¯
- ç”¨æˆ·å¯é¢„ä¼°ç­‰å¾…æ—¶é—´

### 2. é”™è¯¯å‹å¥½æç¤º

**æ¡ˆä¾‹ï¼šAPIè°ƒç”¨æŠ€èƒ½**

```python
class APICallingSkill:
    def __init__(self):
        self.error_messages = {
            "network_error": {
                "user_message": "ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®",
                "developer_message": "HTTPè¯·æ±‚è¶…æ—¶æˆ–è¿æ¥é”™è¯¯",
                "suggestion": "è¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥"
            },
            "api_limit": {
                "user_message": "APIè°ƒç”¨æ¬¡æ•°å·²è¾¾ä¸Šé™",
                "developer_message": "APIé€Ÿç‡é™åˆ¶è§¦å‘",
                "suggestion": "è¯·ç­‰å¾…é™åˆ¶é‡ç½®æˆ–å‡çº§APIå¥—é¤"
            },
            "invalid_input": {
                "user_message": "è¾“å…¥å‚æ•°æ ¼å¼ä¸æ­£ç¡®",
                "developer_message": "è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥",
                "suggestion": "è¯·æ£€æŸ¥è¾“å…¥å‚æ•°æ ¼å¼å’Œç±»å‹"
            }
        }
    
    def handle_error(self, error_type: str, original_error: Exception = None) -> Dict:
        """å‹å¥½çš„é”™è¯¯å¤„ç†"""
        error_info = self.error_messages.get(error_type, {
            "user_message": "æ“ä½œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•",
            "developer_message": str(original_error),
            "suggestion": "è¯·è”ç³»æŠ€æœ¯æ”¯æŒ"
        })
        
        return {
            "success": False,
            "error": {
                "type": error_type,
                "user_message": error_info["user_message"],
                "developer_message": error_info["developer_message"],
                "suggestion": error_info["suggestion"],
                "original_error": str(original_error) if original_error else None
            }
        }
```

**ç”¨æˆ·ä½“éªŒä¼˜åŠ¿**ï¼š
- ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
- æ˜ç¡®çš„è§£å†³å»ºè®®
- æŠ€æœ¯æ”¯æŒä¿¡æ¯

## ğŸ§ª æµ‹è¯•æœ€ä½³å®è·µ

### 1. å…¨é¢æµ‹è¯•è¦†ç›–

**æ¡ˆä¾‹ï¼šæ•°æ®å¤„ç†æŠ€èƒ½æµ‹è¯•**

```python
import pytest
from unittest.mock import Mock, patch
from main import DataProcessingSkill

class TestDataProcessingSkill:
    """æ•°æ®å¤„ç†æŠ€èƒ½æµ‹è¯•å¥—ä»¶"""
    
    def setup_method(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.skill = DataProcessingSkill()
    
    def test_normal_processing(self):
        """æµ‹è¯•æ­£å¸¸æ•°æ®å¤„ç†"""
        input_data = {"numbers": [1, 2, 3, 4, 5]}
        result = self.skill.execute(input_data)
        
        assert result["success"] is True
        assert "result" in result
        assert result["result"]["sum"] == 15
    
    def test_empty_input(self):
        """æµ‹è¯•ç©ºè¾“å…¥å¤„ç†"""
        result = self.skill.execute({})
        
        assert result["success"] is False
        assert "error" in result
    
    @pytest.mark.parametrize("input_data,expected", [
        ({"numbers": [1, 2, 3]}, 6),
        ({"numbers": [10, 20]}, 30),
        ({"numbers": [-1, 1]}, 0),
    ])
    def test_parameterized_processing(self, input_data, expected):
        """å‚æ•°åŒ–æµ‹è¯•"""
        result = self.skill.execute(input_data)
        assert result["result"]["sum"] == expected
    
    @patch('main.ExternalAPI.call')
    def test_external_api_mocking(self, mock_api):
        """æµ‹è¯•å¤–éƒ¨APIæ¨¡æ‹Ÿ"""
        # è®¾ç½®æ¨¡æ‹Ÿè¿”å›å€¼
        mock_api.return_value = {"status": "success", "data": "mocked"}
        
        result = self.skill.execute({"use_external": True})
        
        # éªŒè¯APIè¢«è°ƒç”¨
        mock_api.assert_called_once()
        assert result["success"] is True
    
    @pytest.mark.asyncio
    async def test_async_processing(self):
        """æµ‹è¯•å¼‚æ­¥å¤„ç†"""
        input_data = {"async": True}
        result = await self.skill.execute_async(input_data)
        
        assert result["success"] is True

    def test_performance(self):
        """æ€§èƒ½æµ‹è¯•"""
        import time
        
        start_time = time.time()
        
        # æ‰§è¡Œæ€§èƒ½æ•æ„Ÿæ“ä½œ
        for i in range(1000):
            self.skill.execute({"numbers": [i, i+1, i+2]})
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # æ€§èƒ½æ–­è¨€ï¼š1000æ¬¡æ“ä½œåº”åœ¨2ç§’å†…å®Œæˆ
        assert execution_time < 2.0, f"æ€§èƒ½ä¸è¾¾æ ‡: {execution_time}ç§’"
```

**æµ‹è¯•ä¼˜åŠ¿**ï¼š
- å…¨é¢çš„æµ‹è¯•è¦†ç›–
- å‚æ•°åŒ–æµ‹è¯•å‡å°‘é‡å¤ä»£ç 
- æ¨¡æ‹Ÿå¤–éƒ¨ä¾èµ–
- æ€§èƒ½æµ‹è¯•é›†æˆ

## ğŸ“Š ç›‘æ§ä¸æ—¥å¿—æœ€ä½³å®è·µ

### 1. ç»“æ„åŒ–æ—¥å¿—

**æ¡ˆä¾‹ï¼šç”Ÿäº§ç¯å¢ƒæŠ€èƒ½æ—¥å¿—**

```python
import logging
import json
from datetime import datetime

class StructuredLogger:
    def __init__(self, skill_name: str):
        self.logger = logging.getLogger(skill_name)
        self.skill_name = skill_name
    
    def log_execution(self, input_data: Dict, result: Dict, execution_time: float):
        """ç»“æ„åŒ–æ‰§è¡Œæ—¥å¿—"""
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "skill": self.skill_name,
            "level": "INFO",
            "event": "skill_execution",
            "input_data_size": len(str(input_data)),
            "success": result.get("success", False),
            "execution_time": execution_time,
            "error": result.get("error"),
            "metadata": {
                "skill_version": "1.0.0",
                "environment": "production"
            }
        }
        
        self.logger.info(json.dumps(log_entry))
    
    def log_error(self, error: Exception, context: Dict = None):
        """ç»“æ„åŒ–é”™è¯¯æ—¥å¿—"""
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "skill": self.skill_name,
            "level": "ERROR",
            "event": "skill_error",
            "error_type": type(error).__name__,
            "error_message": str(error),
            "context": context or {},
            "stack_trace": self._get_stack_trace(error)
        }
        
        self.logger.error(json.dumps(log_entry))
```

**ç›‘æ§ä¼˜åŠ¿**ï¼š
- ç»“æ„åŒ–æ—¥å¿—ä¾¿äºåˆ†æ
- å®Œæ•´çš„æ‰§è¡Œä¸Šä¸‹æ–‡
- é”™è¯¯è¿½è¸ªèƒ½åŠ›

## ğŸš€ éƒ¨ç½²ä¸è¿ç»´æœ€ä½³å®è·µ

### 1. å¥åº·æ£€æŸ¥

**æ¡ˆä¾‹ï¼šæŠ€èƒ½å¥åº·ç›‘æ§**

```python
import psutil
import requests
from typing import Dict, List

class SkillHealthMonitor:
    def __init__(self, skill_name: str):
        self.skill_name = skill_name
    
    def check_health(self) -> Dict:
        """å…¨é¢å¥åº·æ£€æŸ¥"""
        checks = [
            self._check_memory_usage(),
            self._check_cpu_usage(),
            self._check_disk_space(),
            self._check_external_dependencies(),
            self._check_skill_functionality()
        ]
        
        # æ±‡æ€»æ£€æŸ¥ç»“æœ
        all_healthy = all(check["healthy"] for check in checks)
        
        return {
            "skill": self.skill_name,
            "healthy": all_healthy,
            "timestamp": datetime.utcnow().isoformat(),
            "checks": checks
        }
    
    def _check_memory_usage(self) -> Dict:
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨"""
        memory_percent = psutil.virtual_memory().percent
        healthy = memory_percent < 80  # 80%é˜ˆå€¼
        
        return {
            "check": "memory_usage",
            "healthy": healthy,
            "details": {
                "memory_percent": memory_percent,
                "threshold": 80
            }
        }
    
    def _check_external_dependencies(self) -> Dict:
        """æ£€æŸ¥å¤–éƒ¨ä¾èµ–"""
        dependencies = [
            ("API Service", "https://api.example.com/health"),
            ("Database", "postgresql://localhost:5432"),
        ]
        
        results = []
        for name, endpoint in dependencies:
            try:
                response = requests.get(endpoint, timeout=5)
                healthy = response.status_code == 200
            except Exception:
                healthy = False
            
            results.append({"name": name, "healthy": healthy})
        
        all_healthy = all(result["healthy"] for result in results)
        
        return {
            "check": "external_dependencies",
            "healthy": all_healthy,
            "details": {"dependencies": results}
        }
```

**è¿ç»´ä¼˜åŠ¿**ï¼š
- å…¨é¢çš„å¥åº·ç›‘æ§
- è‡ªåŠ¨åŒ–æ•…éšœæ£€æµ‹
- è¿ç»´å‹å¥½çš„çŠ¶æ€æŠ¥å‘Š

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ

### ä¼˜åŒ–å‰åå¯¹æ¯”

| ä¼˜åŒ–æªæ–½ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡å¹…åº¦ |
|---------|--------|--------|----------|
| å¼‚æ­¥å¤„ç† | 10ç§’/100è¯·æ±‚ | 2ç§’/100è¯·æ±‚ | 5å€ |
| ç¼“å­˜ç­–ç•¥ | 95%è®¡ç®—æ—¶é—´ | 5%è®¡ç®—æ—¶é—´ | 19å€ |
| æ‰¹é‡å¤„ç† | 10ç§’/100å›¾åƒ | 2ç§’/100å›¾åƒ | 5å€ |
| å†…å­˜ä¼˜åŒ– | 500MBå³°å€¼ | 100MBå³°å€¼ | 5å€ |

## ğŸ¯ å…³é”®æˆåŠŸå› ç´ 

1. **ä»£ç è´¨é‡**ï¼šéµå¾ªSOLIDåŸåˆ™ï¼Œä¿æŒä»£ç ç®€æ´æ¸…æ™°
2. **æ€§èƒ½æ„è¯†**ï¼šä»è®¾è®¡é˜¶æ®µå°±è€ƒè™‘æ€§èƒ½ä¼˜åŒ–
3. **å®‰å…¨ç¬¬ä¸€**ï¼šå¤šå±‚é˜²æŠ¤ï¼Œè¾“å…¥éªŒè¯ï¼Œæƒé™æ§åˆ¶
4. **ç”¨æˆ·ä½“éªŒ**ï¼šåŠæ—¶åé¦ˆï¼Œå‹å¥½é”™è¯¯ï¼Œæ˜ç¡®æŒ‡å¼•
5. **å¯ç»´æŠ¤æ€§**ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œå®Œæ•´æ–‡æ¡£ï¼Œå…¨é¢æµ‹è¯•
6. **å¯è§‚æµ‹æ€§**ï¼šç»“æ„åŒ–æ—¥å¿—ï¼Œå¥åº·æ£€æŸ¥ï¼Œç›‘æ§æŒ‡æ ‡

---

**ç‰ˆæœ¬**: 1.0.0  
**æœ€åæ›´æ–°**: 2024-01-27  
**ä½œè€…**: Py Copilotå¼€å‘å›¢é˜Ÿ