"""å¯¹è¯ç®¡ç†ç›¸å…³APIè·¯ç”±ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
import asyncio
import json
from datetime import datetime
from typing import Any, List, Dict, Optional

from fastapi import APIRouter, HTTPException, Query, status, Body, Depends
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from sqlalchemy import and_

from app.core.database import get_db
from app.modules.conversation.schemas.conversation import SendMessageRequest
from app.modules.llm.services.llm_service_enhanced import enhanced_llm_service
from app.modules.llm.services.llm_tasks import llm_tasks
from app.models.supplier_db import SupplierDB, ModelDB
from app.models.model_capability import ModelCapability, ModelCapabilityAssociation

# å¯¼å…¥æ€ç»´é“¾ç”Ÿæˆå‡½æ•°
def generate_thinking_chain_steps(content: str) -> List[str]:
    """æ ¹æ®æ¶ˆæ¯å†…å®¹ç”Ÿæˆæ€ç»´é“¾æ­¥éª¤"""
    content_lower = content.lower()
    
    if any(word in content_lower for word in ['è®¡ç®—', 'æ•°å­¦', 'å…¬å¼', 'ç­‰äº', 'åŠ ', 'å‡', 'ä¹˜', 'é™¤']):
        return [
            "ğŸ§® è¯†åˆ«æ•°å­¦è®¡ç®—é—®é¢˜...",
            "ğŸ”¢ è§£ææ•°å­¦è¡¨è¾¾å¼...",
            "ğŸ“Š æ‰§è¡Œè®¡ç®—æ­¥éª¤...",
            "âœ… éªŒè¯è®¡ç®—ç»“æœ..."
        ]
    elif any(word in content_lower for word in ['è§£é‡Š', 'ä»€ä¹ˆæ˜¯', 'å®šä¹‰', 'æ¦‚å¿µ']):
        return [
            "ğŸ“š è¯†åˆ«æ¦‚å¿µè§£é‡Šéœ€æ±‚...",
            "ğŸ” æ£€ç´¢ç›¸å…³çŸ¥è¯†åº“...",
            "ğŸ’¡ æ„å»ºè§£é‡Šæ¡†æ¶...",
            "ğŸ“ ç»„ç»‡è§£é‡Šå†…å®¹..."
        ]
    elif any(word in content_lower for word in ['ä»£ç ', 'ç¼–ç¨‹', 'å‡½æ•°', 'å˜é‡']):
        return [
            "ğŸ’» åˆ†æç¼–ç¨‹é—®é¢˜...",
            "ğŸ”§ è®¾è®¡è§£å†³æ–¹æ¡ˆ...",
            "ğŸ“‹ ç¼–å†™ä»£ç é€»è¾‘...",
            "âœ… éªŒè¯ä»£ç æ­£ç¡®æ€§..."
        ]
    elif any(word in content_lower for word in ['ç¿»è¯‘', 'è¯­è¨€', 'è‹±æ–‡', 'ä¸­æ–‡']):
        return [
            "ğŸŒ è¯†åˆ«ç¿»è¯‘éœ€æ±‚...",
            "ğŸ“– åˆ†æåŸæ–‡è¯­ä¹‰...",
            "ğŸ”„ æ„å»ºç¿»è¯‘æ˜ å°„...",
            "âœï¸ ä¼˜åŒ–ç¿»è¯‘è¡¨è¾¾..."
        ]
    else:
        return []

router = APIRouter()


# æ¨¡æ‹Ÿå†…å­˜å­˜å‚¨
class MockStorage:
    def __init__(self):
        self.conversations = []
        self.messages = []
        self.conversation_id_counter = 1
        self.message_id_counter = 1
        self.topics = []  # è¯é¢˜åˆ—è¡¨
        self.topic_id_counter = 1
    
    def create_conversation(self, title: str = "æ–°å¯¹è¯", description: str = "") -> Dict[str, Any]:
        conversation = {
            "id": self.conversation_id_counter,
            "title": title,
            "description": description,
            "is_active": True,
            "message_count": 0,
            "created_at": datetime.utcnow(),
            "updated_at": datetime.utcnow(),
            "last_message_at": None
        }
        self.conversations.append(conversation)
        self.conversation_id_counter += 1
        return conversation
    
    def get_conversation(self, conversation_id: int) -> Optional[Dict[str, Any]]:
        for conv in self.conversations:
            if conv["id"] == conversation_id:
                return conv
        return None
    
    def update_conversation(self, conversation_id: int, update_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        conv = self.get_conversation(conversation_id)
        if conv:
            for field, value in update_data.items():
                if field in conv:
                    conv[field] = value
            conv["updated_at"] = datetime.utcnow()
        return conv
    
    def delete_conversation(self, conversation_id: int) -> None:
        self.conversations = [conv for conv in self.conversations if conv["id"] != conversation_id]
        self.messages = [msg for msg in self.messages if msg["conversation_id"] != conversation_id]
    
    def create_message(self, conversation_id: int, content: str, role: str) -> Dict[str, Any]:
        message = {
            "id": self.message_id_counter,
            "conversation_id": conversation_id,
            "content": content,
            "role": role,
            "is_visible": True,
            "created_at": datetime.utcnow()
        }
        self.messages.append(message)
        self.message_id_counter += 1
        
        # æ›´æ–°å¯¹è¯æ¶ˆæ¯è®¡æ•°å’Œæœ€åæ¶ˆæ¯æ—¶é—´
        conv = self.get_conversation(conversation_id)
        if conv:
            conv["message_count"] = sum(1 for msg in self.messages if msg["conversation_id"] == conversation_id)
            conv["last_message_at"] = datetime.utcnow()
        
        return message
    
    def get_conversation_messages(self, conversation_id: int, skip: int = 0, limit: int = 50) -> List[Dict[str, Any]]:
        messages = [msg for msg in self.messages if msg["conversation_id"] == conversation_id and msg["is_visible"]]
        messages.sort(key=lambda x: x["created_at"])
        return messages[skip:skip+limit]
    
    def get_all_conversations(self, skip: int = 0, limit: int = 20) -> List[Dict[str, Any]]:
        conversations = sorted(
            self.conversations,
            key=lambda x: (x["last_message_at"] or datetime.min, x["created_at"]),
            reverse=True
        )
        return conversations[skip:skip+limit]
    
    # è¯é¢˜ç®¡ç†æ–¹æ³•
    def create_topic(self, title: str, description: str = "", conversation_id: Optional[int] = None) -> Dict[str, Any]:
        """åˆ›å»ºè¯é¢˜"""
        topic = {
            "id": self.topic_id_counter,
            "title": title,
            "description": description,
            "conversation_id": conversation_id,
            "created_at": datetime.utcnow(),
            "updated_at": datetime.utcnow(),
            "is_active": True
        }
        self.topics.append(topic)
        self.topic_id_counter += 1
        return topic
    
    def get_topic(self, topic_id: int) -> Optional[Dict[str, Any]]:
        """è·å–è¯é¢˜"""
        for topic in self.topics:
            if topic["id"] == topic_id:
                return topic
        return None
    
    def get_topics_by_conversation(self, conversation_id: int) -> List[Dict[str, Any]]:
        """è·å–å¯¹è¯çš„æ‰€æœ‰è¯é¢˜"""
        return [topic for topic in self.topics if topic["conversation_id"] == conversation_id]
    
    def update_topic(self, topic_id: int, update_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æ›´æ–°è¯é¢˜"""
        topic = self.get_topic(topic_id)
        if topic:
            for field, value in update_data.items():
                if field in topic:
                    topic[field] = value
            topic["updated_at"] = datetime.utcnow()
        return topic
    
    def delete_topic(self, topic_id: int) -> None:
        """åˆ é™¤è¯é¢˜"""
        self.topics = [topic for topic in self.topics if topic["id"] != topic_id]
    
    def switch_topic(self, conversation_id: int, topic_id: int) -> bool:
        """åˆ‡æ¢åˆ°æŒ‡å®šè¯é¢˜"""
        # å°†æ‰€æœ‰è¯é¢˜è®¾ç½®ä¸ºéæ´»è·ƒçŠ¶æ€
        for topic in self.topics:
            if topic["conversation_id"] == conversation_id:
                topic["is_active"] = False
        
        # æ¿€æ´»æŒ‡å®šè¯é¢˜
        target_topic = self.get_topic(topic_id)
        if target_topic and target_topic["conversation_id"] == conversation_id:
            target_topic["is_active"] = True
            target_topic["updated_at"] = datetime.utcnow()
            return True
        return False
    
    def get_active_topic(self, conversation_id: int) -> Optional[Dict[str, Any]]:
        """è·å–å½“å‰æ´»è·ƒè¯é¢˜"""
        for topic in self.topics:
            if topic["conversation_id"] == conversation_id and topic["is_active"]:
                return topic
        return None

# åˆ›å»ºæ¨¡æ‹Ÿå­˜å‚¨å®ä¾‹
mock_storage = MockStorage()


@router.post("/")
async def create_conversation(
    title: str = "æ–°å¯¹è¯",
    description: str = "",
    initial_message: Optional[str] = None
) -> Dict[str, Any]:
    """
    åˆ›å»ºæ–°å¯¹è¯
    """
    conversation = mock_storage.create_conversation(title, description)
    
    # å¦‚æœæä¾›äº†åˆå§‹æ¶ˆæ¯
    if initial_message:
        mock_storage.create_message(conversation["id"], initial_message, "user")
        conversation = mock_storage.get_conversation(conversation["id"])
    
    return conversation


@router.get("/")
async def list_conversations(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100)
) -> Dict[str, Any]:
    """
    è·å–å¯¹è¯åˆ—è¡¨
    """
    offset = (page - 1) * page_size
    conversations = mock_storage.get_all_conversations(skip=offset, limit=page_size)
    total = len(mock_storage.conversations)
    
    return {
        "conversations": conversations,
        "total": total,
        "page": page,
        "page_size": page_size
    }


@router.get("/{conversation_id}")
async def get_conversation_detail(conversation_id: int) -> Dict[str, Any]:
    """
    è·å–å¯¹è¯è¯¦æƒ…åŠæ¶ˆæ¯å†å²
    """
    conversation = mock_storage.get_conversation(conversation_id)
    if not conversation:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="å¯¹è¯ä¸å­˜åœ¨"
        )
    
    # è·å–æ‰€æœ‰æ¶ˆæ¯
    messages = mock_storage.get_conversation_messages(conversation_id, limit=1000)
    
    return {
        **conversation,
        "messages": messages
    }


@router.put("/{conversation_id}")
async def update_conversation(
    conversation_id: int,
    title: Optional[str] = None,
    description: Optional[str] = None,
    is_active: Optional[bool] = None
) -> Dict[str, Any]:
    """
    æ›´æ–°å¯¹è¯ä¿¡æ¯
    """
    conversation = mock_storage.get_conversation(conversation_id)
    if not conversation:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="å¯¹è¯ä¸å­˜åœ¨"
        )
    
    update_data = {}
    if title is not None:
        update_data["title"] = title
    if description is not None:
        update_data["description"] = description
    if is_active is not None:
        update_data["is_active"] = is_active
    
    updated_conversation = mock_storage.update_conversation(conversation_id, update_data)
    return updated_conversation


@router.delete("/{conversation_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_conversation(conversation_id: int) -> None:
    """
    åˆ é™¤å¯¹è¯
    """
    conversation = mock_storage.get_conversation(conversation_id)
    if not conversation:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="å¯¹è¯ä¸å­˜åœ¨"
        )
    
    mock_storage.delete_conversation(conversation_id)


@router.post("/{conversation_id}/messages")
async def send_message(
    conversation_id: int,
    request: SendMessageRequest = Body(...),
    db: Session = Depends(get_db)
) -> Dict[str, Any]:
    """
    åœ¨å¯¹è¯ä¸­å‘é€æ¶ˆæ¯
    """
    # æŸ¥è¯¢å¯¹è¯
    conversation = mock_storage.get_conversation(conversation_id)
    if not conversation:
        # å¦‚æœå¯¹è¯ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªæ–°å¯¹è¯
        conversation = mock_storage.create_conversation(title=f"å¯¹è¯ {conversation_id}")
        print(f"å·²è‡ªåŠ¨åˆ›å»ºå¯¹è¯: {conversation}")
    
    if not conversation.get("is_active", True):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="å¯¹è¯å·²è¢«å…³é—­"
        )
    
    # åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
    user_message = mock_storage.create_message(conversation_id, request.content, "user")
    
    # å¦‚æœéœ€è¦ä½¿ç”¨LLMç”Ÿæˆå›å¤
    assistant_message = None
    if request.use_llm:
        try:
            # è·å–å¯¹è¯å†å²
            conversation_history = mock_storage.get_conversation_messages(conversation_id)
            
            # æ„å»ºèŠå¤©æ¶ˆæ¯åˆ—è¡¨
            chat_messages = [
                {"role": msg["role"], "content": msg["content"]}
                for msg in conversation_history
            ]
            chat_messages.append({"role": "user", "content": request.content})
            
            # ä½¿ç”¨LLMç”Ÿæˆå›å¤
            try:
                # ä½¿ç”¨è¯·æ±‚ä¸­çš„æ¨¡å‹åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
                model_name = request.model_name or "gpt-3.5-turbo"
                print(f"è°ƒç”¨enhanced_llm_service.chat_completionï¼Œæ¨¡å‹: {model_name}")
                print(f"èŠå¤©æ¶ˆæ¯: {chat_messages}")
                print(f"ä¼ é€’çš„agent_idå‚æ•°: {conversation.get('agent_id')}")
                llm_response = enhanced_llm_service.chat_completion(
                    messages=chat_messages,
                    model_name=model_name,
                    db=db,
                    agent_id=conversation.get("agent_id")
                )
                print(f"LLMå“åº”: {llm_response}")
                
                # æ£€æŸ¥LLMè°ƒç”¨æ˜¯å¦æˆåŠŸ
                if llm_response.get("success", True):
                    ai_content = llm_response.get("generated_text", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚")
                    print(f"æå–çš„AIå†…å®¹: {ai_content}")
                else:
                    # å¦‚æœè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤±è´¥åŸå› ä½œä¸ºå›å¤
                    ai_content = llm_response.get("generated_text", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚")
                    print(f"LLMè°ƒç”¨å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯: {ai_content}")
                    # å¦‚æœæœ‰è¯¦ç»†çš„å¤±è´¥åˆ†æï¼Œä¹ŸåŠ å…¥åˆ°å›å¤ä¸­
                    if "failure_analysis" in llm_response:
                        ai_content += f"\n\nè¯¦ç»†åˆ†æ: {llm_response['failure_analysis']}"
            except (AttributeError, TypeError) as e:
                print(f"chat_completionè°ƒç”¨å¤±è´¥: {str(e)}")
                # ä½¿ç”¨é”™è¯¯ä¿¡æ¯ä½œä¸ºå›å¤
                ai_content = f"æŠ±æ­‰ï¼ŒLLMæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}"
            except Exception as e:
                print(f"chat_completionè°ƒç”¨å‘ç”Ÿå…¶ä»–é”™è¯¯: {str(e)}")
                # ä½¿ç”¨é”™è¯¯ä¿¡æ¯ä½œä¸ºå›å¤
                ai_content = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}"
            
            # åˆ›å»ºåŠ©æ‰‹å›å¤æ¶ˆæ¯
            print(f"åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯ï¼Œå†…å®¹: {ai_content}")
            assistant_message = mock_storage.create_message(conversation_id, ai_content, "assistant")
            print(f"åŠ©æ‰‹æ¶ˆæ¯åˆ›å»ºç»“æœ: {assistant_message}")
            
        except Exception as e:
            print(f"LLMç”Ÿæˆå›å¤å¤±è´¥: {str(e)}")
            # å³ä½¿å‘ç”Ÿå¼‚å¸¸ï¼Œä¹Ÿè¦åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿå›å¤
            ai_content = f"è¿™æ˜¯ä¸€æ¡æ¨¡æ‹Ÿå›å¤ï¼ŒåŸºäºæ‚¨çš„æ¶ˆæ¯ï¼š{request.content[:50]}..."
            assistant_message = mock_storage.create_message(conversation_id, ai_content, "assistant")
    
    # æ„å»ºå“åº”
    response = {
        "conversation_id": conversation_id,
        "user_message": user_message,
        "generated_at": datetime.utcnow()
    }
    
    print(f"æ„å»ºå“åº”ï¼Œassistant_messageå­˜åœ¨: {assistant_message is not None}")
    if assistant_message:
        response["assistant_message"] = assistant_message
        print(f"å“åº”ä¸­åŒ…å«åŠ©æ‰‹æ¶ˆæ¯: {response['assistant_message']}")
    
    print(f"æœ€ç»ˆå“åº”: {response}")
    return response


@router.get("/{conversation_id}/messages")
async def get_conversation_messages(
    conversation_id: int,
    page: int = Query(1, ge=1),
    page_size: int = Query(50, ge=1, le=200)
) -> Dict[str, Any]:
    """
    è·å–å¯¹è¯çš„æ¶ˆæ¯å†å²ï¼ˆåˆ†é¡µï¼‰
    """
    # éªŒè¯å¯¹è¯å­˜åœ¨
    conversation = mock_storage.get_conversation(conversation_id)
    if not conversation:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="å¯¹è¯ä¸å­˜åœ¨"
        )
    
    # è®¡ç®—åç§»é‡
    offset = (page - 1) * page_size
    
    # è·å–æ¶ˆæ¯åˆ—è¡¨
    messages = mock_storage.get_conversation_messages(conversation_id, skip=offset, limit=page_size)
    total = sum(1 for msg in mock_storage.messages if msg["conversation_id"] == conversation_id and msg["is_visible"])
    
    return {
        "messages": messages,
        "total": total,
        "page": page,
        "page_size": page_size
    }


@router.post("/{conversation_id}/messages/stream")
async def send_message_stream(
    conversation_id: int,
    body: dict = Body(...),
    db: Session = Depends(get_db)
) -> StreamingResponse:
    """
    åœ¨å¯¹è¯ä¸­å‘é€æ¶ˆæ¯ï¼ˆæµå¼å“åº”ç‰ˆæœ¬ï¼‰
    """
    # éªŒè¯å¯¹è¯å­˜åœ¨
    conversation = mock_storage.get_conversation(conversation_id)
    if not conversation:
        # å¦‚æœå¯¹è¯ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªæ–°å¯¹è¯
        conversation = mock_storage.create_conversation(title=f"å¯¹è¯ {conversation_id}")
        print(f"å·²è‡ªåŠ¨åˆ›å»ºå¯¹è¯: {conversation}")
    
    if not conversation.get("is_active", True):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="å¯¹è¯å·²è¢«å…³é—­"
        )
    
    # æå–å‚æ•°
    content = body.get("content", "")
    use_llm = body.get("use_llm", True)
    model_name = body.get("model_name")
    enable_thinking_chain = body.get("enable_thinking_chain", False)
    
    # åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
    user_message = mock_storage.create_message(conversation_id, content, "user")
    
    async def stream_generator():
        try:
            # å‘é€ç”¨æˆ·æ¶ˆæ¯ç¡®è®¤
            yield "data: {\"type\": \"user_message\", \"content\": \"æ¶ˆæ¯å·²æ”¶åˆ°\", \"message_id\": 1}\n\n"
            
            if use_llm:
                # é¦–å…ˆè·å–å¯¹è¯å†å²
                conversation_history = mock_storage.get_conversation_messages(conversation_id)
                
                # æ„å»ºèŠå¤©æ¶ˆæ¯åˆ—è¡¨
                chat_messages = [
                    {"role": msg["role"], "content": msg["content"]}
                    for msg in conversation_history
                ]
                chat_messages.append({"role": "user", "content": content})
                
                # ä½¿ç”¨LLMç”Ÿæˆå›å¤
                ai_content = ""
                reasoning_content = ""
                try:
                    # ä½¿ç”¨è¯·æ±‚ä¸­çš„æ¨¡å‹åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
                    llm_model_name = model_name or "gpt-3.5-turbo"
                    print(f"è°ƒç”¨enhanced_llm_service.chat_completionï¼Œæ¨¡å‹: {llm_model_name}")
                    print(f"èŠå¤©æ¶ˆæ¯: {chat_messages}")
                    
                    llm_response = enhanced_llm_service.chat_completion(
                        messages=chat_messages,
                        model_name=llm_model_name,
                        db=db,
                        agent_id=conversation.get("agent_id")
                    )
                    
                    print(f"LLMå“åº”ç±»å‹: {type(llm_response)}")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æµå¼å“åº”ç”Ÿæˆå™¨
                    if hasattr(llm_response, '__iter__') and not isinstance(llm_response, (list, dict)):
                        print("æ£€æµ‹åˆ°æµå¼å“åº”ç”Ÿæˆå™¨")
                        full_ai_content = ""
                        full_reasoning_content = ""
                        
                        # å®æ—¶è½¬å‘æµå¼å“åº”å—ï¼Œé¿å…ç­‰å¾…æ—¶é—´åŠ å€
                        for chunk in llm_response:
                            print(f"å®æ—¶è½¬å‘æµå¼å—: {chunk}")
                            
                            if chunk["type"] == "thinking":
                                # ç´¯ç§¯æ€ç»´é“¾ä¿¡æ¯å¹¶å®æ—¶è½¬å‘
                                full_reasoning_content += chunk['content']
                                # å®æ—¶å‘é€ç´¯ç§¯çš„æ€ç»´é“¾ä¿¡æ¯
                                yield f"data: {json.dumps({'type': 'thinking', 'content': full_reasoning_content})}\n\n"
                            elif chunk["type"] == "content":
                                # ç´¯ç§¯å†…å®¹ä¿¡æ¯å¹¶å®æ—¶è½¬å‘
                                full_ai_content += chunk['content']
                                # å®æ—¶å‘é€ç´¯ç§¯çš„å†…å®¹ä¿¡æ¯
                                yield f"data: {json.dumps({'type': 'content', 'content': full_ai_content})}\n\n"
                            
                            # æ§åˆ¶å‘é€é€Ÿåº¦
                            await asyncio.sleep(0.05)
                        
                        ai_content = full_ai_content
                    else:
                        # å¤„ç†éæµå¼å“åº”
                        print(f"LLMå“åº”: {llm_response}")
                        
                        # æ£€æŸ¥LLMè°ƒç”¨æ˜¯å¦æˆåŠŸ
                        if llm_response.get("success", True):
                            ai_content = llm_response.get("generated_text", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚")
                            print(f"æå–çš„AIå†…å®¹: {ai_content}")
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰æ€ç»´é“¾ä¿¡æ¯
                            reasoning_content = llm_response.get("reasoning_content", "")
                            print(f"æå–çš„æ€ç»´é“¾å†…å®¹: {reasoning_content}")
                        else:
                            # å¦‚æœè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤±è´¥åŸå› ä½œä¸ºå›å¤
                            ai_content = llm_response.get("generated_text", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚")
                            print(f"LLMè°ƒç”¨å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯: {ai_content}")
                            # å¦‚æœæœ‰è¯¦ç»†çš„å¤±è´¥åˆ†æï¼Œä¹ŸåŠ å…¥åˆ°å›å¤ä¸­
                            if "failure_analysis" in llm_response:
                                ai_content += f"\n\nè¯¦ç»†åˆ†æ: {llm_response['failure_analysis']}"
                        
                        # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†æ€ç»´é“¾ï¼Œå¦‚æœå¯ç”¨åˆ™å‘é€æ€ç»´é“¾ä¿¡æ¯
                        if enable_thinking_chain and reasoning_content:
                            # å¦‚æœæœ‰æ€ç»´é“¾ä¿¡æ¯ï¼Œå‘é€ç»™å‰ç«¯
                            yield f"data: {json.dumps({'type': 'thinking', 'content': reasoning_content})}\n\n"
                            await asyncio.sleep(0.5)  # ç¼©çŸ­ç­‰å¾…æ—¶é—´ï¼Œæé«˜å“åº”é€Ÿåº¦
                        
                        # å¦‚æœè·å–åˆ°äº†å›å¤ï¼Œé€å­—ç¬¦æµå¼å‘é€
                        if ai_content:
                            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´åå†å¼€å§‹å‘é€å†…å®¹
                            await asyncio.sleep(0.5)
                            
                            # é€å­—ç¬¦å‘é€å›å¤å†…å®¹
                            if len(ai_content) < 10:
                                # éå¸¸çŸ­çš„å›å¤
                                yield f"data: {json.dumps({'type': 'content', 'content': ai_content})}\n\n"
                                await asyncio.sleep(0.2)
                            else:
                                # æŒ‰å­—ç¬¦é€ä¸ªå‘é€ï¼Œç¡®ä¿åˆ†å—æ­£ç¡®
                                for i in range(1, len(ai_content) + 1):
                                    current_text = ai_content[:i]
                                    yield f"data: {json.dumps({'type': 'content', 'content': current_text})}\n\n"
                                    # æ§åˆ¶å‘é€é€Ÿåº¦
                                    await asyncio.sleep(0.05)
                except (AttributeError, TypeError) as e:
                    print(f"chat_completionè°ƒç”¨å¤±è´¥: {str(e)}")
                    # ä½¿ç”¨é”™è¯¯ä¿¡æ¯ä½œä¸ºå›å¤
                    ai_content = f"æŠ±æ­‰ï¼ŒLLMæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}"
                    yield f"data: {json.dumps({'type': 'content', 'content': ai_content})}\n\n"
                except Exception as e:
                    print(f"chat_completionè°ƒç”¨å‘ç”Ÿå…¶ä»–é”™è¯¯: {str(e)}")
                    # ä½¿ç”¨é”™è¯¯ä¿¡æ¯ä½œä¸ºå›å¤
                    ai_content = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}"
                    yield f"data: {json.dumps({'type': 'content', 'content': ai_content})}\n\n"
                
                # åˆ›å»ºæœ€ç»ˆçš„åŠ©æ‰‹æ¶ˆæ¯
                if ai_content:
                    mock_storage.create_message(conversation_id, ai_content, "assistant")
                
                # å‘é€å®Œæˆä¿¡å·
                yield "data: {\"type\": \"complete\", \"content\": \"\"}\n\n"
        except Exception as e:
            # å‘é€é”™è¯¯ä¿¡æ¯
            error_msg = f"æµå¼å“åº”ç”Ÿæˆå¤±è´¥: {str(e)}"
            yield f"data: {json.dumps({'type': 'error', 'content': error_msg})}\n\n"
    
    return StreamingResponse(
        stream_generator(),
        media_type="text/event-stream",
        headers={
            "Content-Type": "text/event-stream",
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control, Content-Type",
            "X-Accel-Buffering": "no"
        }
    )


@router.get("/models/conversation")
async def get_conversation_models(db: Session = Depends(get_db)) -> Dict[str, Any]:
    """
    è·å–å·²å¯ç”¨çš„ä¾›åº”å•†çš„å¯¹è¯æ¨¡å‹åˆ—è¡¨
    
    è¿”å›å…·æœ‰å¯¹è¯èƒ½åŠ›çš„æ¨¡å‹åˆ—è¡¨ï¼ŒåŒ…æ‹¬æ¨¡å‹IDã€åç§°ã€ä¾›åº”å•†ä¿¡æ¯ç­‰
    """
    try:
        # è·å–æ‰€æœ‰å·²å¯ç”¨çš„ä¾›åº”å•†
        enabled_suppliers = db.query(SupplierDB).filter(SupplierDB.is_active == True).all()
        enabled_supplier_ids = [s.id for s in enabled_suppliers]
        
        # è·å–æ‰€æœ‰å·²å¯ç”¨çš„ä¾›åº”å•†çš„æ¨¡å‹
        enabled_models = db.query(ModelDB).filter(
            ModelDB.supplier_id.in_(enabled_supplier_ids),
            ModelDB.is_active == True
        ).all()
        
        # æ£€æŸ¥å¯¹è¯ç›¸å…³èƒ½åŠ›
        conversation_capabilities = db.query(ModelCapability).filter(
            ModelCapability.name.ilike("%conversation%") | 
            ModelCapability.name.ilike("%chat%") |
            ModelCapability.name.ilike("%å¯¹è¯%") |
            ModelCapability.display_name.ilike("%å¯¹è¯%")
        ).all()
        
        conversation_capability_ids = [c.id for c in conversation_capabilities]
        
        # ç­›é€‰å…·æœ‰å¯¹è¯èƒ½åŠ›çš„æ¨¡å‹
        conversation_models = []
        
        for model in enabled_models:
            # æ£€æŸ¥æ¨¡å‹çš„èƒ½åŠ›å…³è”
            associations = db.query(ModelCapabilityAssociation).filter(
                ModelCapabilityAssociation.model_id == model.id
            ).all()
            
            # è·å–æ¨¡å‹å¯¹åº”çš„èƒ½åŠ›
            model_capabilities = []
            for assoc in associations:
                capability = db.query(ModelCapability).filter(
                    ModelCapability.id == assoc.capability_id
                ).first()
                if capability:
                    model_capabilities.append(capability)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹è¯ç›¸å…³èƒ½åŠ›
            has_conversation = False
            for capability in model_capabilities:
                if any(keyword in capability.name.lower() for keyword in ['conversation', 'chat', 'å¯¹è¯']) or \
                   any(keyword in capability.display_name.lower() for keyword in ['å¯¹è¯']):
                    has_conversation = True
                    break
            
            # å¦‚æœæ¨¡å‹æ²¡æœ‰æ˜ç¡®çš„èƒ½åŠ›å…³è”ï¼Œå‡è®¾æ‰€æœ‰è¯­è¨€æ¨¡å‹éƒ½æœ‰å¯¹è¯èƒ½åŠ›
            if not model_capabilities and model.model_name and any(keyword in model.model_name.lower() for keyword in ['chat', 'å¯¹è¯', 'conversation']):
                has_conversation = True
            
            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„èƒ½åŠ›å…³è”ï¼Œä½†æ¨¡å‹æ˜¯è¯­è¨€æ¨¡å‹ï¼Œä¹Ÿå‡è®¾æœ‰å¯¹è¯èƒ½åŠ›
            if not model_capabilities and not has_conversation:
                # æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦åŒ…å«å¸¸è§è¯­è¨€æ¨¡å‹å…³é”®è¯
                language_model_keywords = ['gpt', 'claude', 'gemini', 'llama', 'qwen', 'deepseek', 'glm', 'kimi', 'moonshot', 'baidu', 'tencent', '360', 'xunfei', 'jd', 'kuaishou', 'doubao', 'abab']
                if any(keyword in model.model_name.lower() for keyword in language_model_keywords):
                    has_conversation = True
            
            supplier = db.query(SupplierDB).filter(SupplierDB.id == model.supplier_id).first()
            
            if has_conversation:
                # æ„å»ºæ¨¡å‹LOGOè·¯å¾„
                model_logo = None
                if model.logo:
                    if model.logo.startswith('http'):
                        model_logo = model.logo
                    elif model.logo.startswith('/'):
                        # å¦‚æœæ˜¯ç»å¯¹è·¯å¾„ï¼Œä¿æŒåŸæ ·
                        model_logo = model.logo
                    else:
                        # ç›¸å¯¹è·¯å¾„ï¼Œæ·»åŠ å®Œæ•´è·¯å¾„
                        model_logo = f"/logos/models/{model.logo}"
                
                # æ„å»ºä¾›åº”å•†LOGOè·¯å¾„
                supplier_logo = None
                if supplier and supplier.logo:
                    if supplier.logo.startswith('http'):
                        supplier_logo = supplier.logo
                    elif supplier.logo.startswith('/'):
                        # å¦‚æœæ˜¯ç»å¯¹è·¯å¾„ï¼Œä¿æŒåŸæ ·
                        supplier_logo = supplier.logo
                    else:
                        # ç›¸å¯¹è·¯å¾„ï¼Œæ·»åŠ å®Œæ•´è·¯å¾„
                        supplier_logo = f"/logos/providers/{supplier.logo}"
                
                conversation_models.append({
                    'id': model.id,
                    'model_id': model.model_id,
                    'model_name': model.model_name,
                    'description': model.description,
                    'logo': model_logo,
                    'supplier_id': model.supplier_id,
                    'supplier_name': supplier.name if supplier else "æœªçŸ¥ä¾›åº”å•†",
                    'supplier_display_name': supplier.display_name if supplier else "æœªçŸ¥ä¾›åº”å•†",
                    'supplier_logo': supplier_logo,
                    'is_default': model.is_default,
                    'capabilities': [{
                        'id': c.id,
                        'name': c.name,
                        'display_name': c.display_name
                    } for c in model_capabilities]
                })
        
        # æŒ‰æ¨¡å‹åç§°æ’åº
        conversation_models.sort(key=lambda x: x['model_name'])
        
        return {
            "status": "success",
            "message": f"æˆåŠŸè·å– {len(conversation_models)} ä¸ªå¯¹è¯æ¨¡å‹",
            "models": conversation_models,
            "total": len(conversation_models)
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–å¯¹è¯æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


# è¯é¢˜ç®¡ç†API
@router.post("/{conversation_id}/topics")
async def create_topic(
    conversation_id: int,
    title: str = Body(..., description="è¯é¢˜æ ‡é¢˜"),
    description: str = Body("", description="è¯é¢˜æè¿°")
) -> Dict[str, Any]:
    """
    ä¸ºå¯¹è¯åˆ›å»ºæ–°è¯é¢˜
    """
    # éªŒè¯å¯¹è¯å­˜åœ¨
    conversation = mock_storage.get_conversation(conversation_id)
    if not conversation:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="å¯¹è¯ä¸å­˜åœ¨"
        )
    
    # åˆ›å»ºè¯é¢˜
    topic = mock_storage.create_topic(title, description, conversation_id)
    return {
        "status": "success",
        "topic": topic
    }


@router.get("/{conversation_id}/topics")
async def list_topics(conversation_id: int) -> Dict[str, Any]:
    """
    è·å–å¯¹è¯çš„æ‰€æœ‰è¯é¢˜
    """
    # å³ä½¿å¯¹è¯ä¸å­˜åœ¨ï¼Œä¹Ÿè¿”å›ç©ºè¯é¢˜åˆ—è¡¨è€Œä¸æ˜¯404
    # è·å–è¯é¢˜åˆ—è¡¨
    topics = mock_storage.get_topics_by_conversation(conversation_id)
    return {
        "status": "success",
        "topics": topics
    }


@router.put("/{conversation_id}/topics/{topic_id}")
async def update_topic(
    conversation_id: int,
    topic_id: int,
    title: Optional[str] = Body(None, description="æ–°æ ‡é¢˜"),
    description: Optional[str] = Body(None, description="æ–°æè¿°")
) -> Dict[str, Any]:
    """
    æ›´æ–°è¯é¢˜ä¿¡æ¯
    """
    # éªŒè¯å¯¹è¯å­˜åœ¨
    conversation = mock_storage.get_conversation(conversation_id)
    if not conversation:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="å¯¹è¯ä¸å­˜åœ¨"
        )
    
    # éªŒè¯è¯é¢˜å­˜åœ¨ä¸”å±äºè¯¥å¯¹è¯
    topic = mock_storage.get_topic(topic_id)
    if not topic or topic["conversation_id"] != conversation_id:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="è¯é¢˜ä¸å­˜åœ¨"
        )
    
    # æ›´æ–°è¯é¢˜
    update_data = {}
    if title is not None:
        update_data["title"] = title
    if description is not None:
        update_data["description"] = description
    
    updated_topic = mock_storage.update_topic(topic_id, update_data)
    return {
        "status": "success",
        "topic": updated_topic
    }


@router.delete("/{conversation_id}/topics/{topic_id}")
async def delete_topic(conversation_id: int, topic_id: int) -> Dict[str, Any]:
    """
    åˆ é™¤è¯é¢˜
    """
    # éªŒè¯å¯¹è¯å­˜åœ¨
    conversation = mock_storage.get_conversation(conversation_id)
    if not conversation:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="å¯¹è¯ä¸å­˜åœ¨"
        )
    
    # éªŒè¯è¯é¢˜å­˜åœ¨ä¸”å±äºè¯¥å¯¹è¯
    topic = mock_storage.get_topic(topic_id)
    if not topic or topic["conversation_id"] != conversation_id:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="è¯é¢˜ä¸å­˜åœ¨"
        )
    
    # åˆ é™¤è¯é¢˜
    mock_storage.delete_topic(topic_id)
    return {
        "status": "success",
        "message": "è¯é¢˜åˆ é™¤æˆåŠŸ"
    }


@router.post("/{conversation_id}/topics/{topic_id}/switch")
async def switch_topic(conversation_id: int, topic_id: int) -> Dict[str, Any]:
    """
    åˆ‡æ¢åˆ°æŒ‡å®šè¯é¢˜
    """
    # éªŒè¯å¯¹è¯å­˜åœ¨
    conversation = mock_storage.get_conversation(conversation_id)
    if not conversation:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="å¯¹è¯ä¸å­˜åœ¨"
        )
    
    # éªŒè¯è¯é¢˜å­˜åœ¨ä¸”å±äºè¯¥å¯¹è¯
    topic = mock_storage.get_topic(topic_id)
    if not topic or topic["conversation_id"] != conversation_id:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="è¯é¢˜ä¸å­˜åœ¨"
        )
    
    # åˆ‡æ¢è¯é¢˜
    success = mock_storage.switch_topic(conversation_id, topic_id)
    if success:
        return {
            "status": "success",
            "message": "è¯é¢˜åˆ‡æ¢æˆåŠŸ",
            "active_topic": mock_storage.get_active_topic(conversation_id)
        }
    else:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="è¯é¢˜åˆ‡æ¢å¤±è´¥"
        )


@router.get("/{conversation_id}/active_topic")
async def get_active_topic(conversation_id: int) -> Dict[str, Any]:
    """
    è·å–å½“å‰æ´»è·ƒè¯é¢˜
    """
    # å³ä½¿å¯¹è¯ä¸å­˜åœ¨ï¼Œä¹Ÿè¿”å›Noneè€Œä¸æ˜¯404
    # è·å–æ´»è·ƒè¯é¢˜
    active_topic = mock_storage.get_active_topic(conversation_id)
    return {
        "status": "success",
        "active_topic": active_topic
    }